<p align="center">
  <h1 align="center">ğŸ“ College Knowledge Retrieval System</h1>
  <p align="center">
    <strong>An AI-powered chatbot that gives college students instant answers from official documents</strong>
  </p>
  <p align="center">
    Built with LLM + RAG (Retrieval-Augmented Generation) Â· Ollama Â· ChromaDB Â· React Â· FastAPI
  </p>
</p>

---

<p align="center">
  <img src="assets/landing_page.png" width="400" alt="Landing Page"/>
  &nbsp;&nbsp;&nbsp;
  <img src="assets/chat_interface.png" width="400" alt="Chat Interface"/>
</p>

## ğŸ§ Why This Project?

College students often struggle to find specific information buried in lengthy policy documents, rulebooks, and scattered PDF files. Questions like:

- *"What's the minimum attendance to sit for exams?"*
- *"What CGPA do I need for placements?"*
- *"How do I apply for a scholarship?"*
- *"What are the hostel mess timings?"*

...usually require digging through multiple documents or asking seniors who may not have accurate answers.

**This project solves that.** It ingests official college documents (PDFs, DOCX, TXT) into a vector database, and uses a locally-running LLM to answer student questions in natural, conversational language â€” with source citations so students can verify the information.

### ğŸ¯ Key Goals

- **Accessibility**: Students get instant, accurate answers without reading 50-page PDFs
- **Privacy**: Everything runs locally â€” no data sent to OpenAI or any cloud service
- **Student-friendly**: Understands slang, abbreviations, and informal language (e.g., "idk", "uk", "wanna")
- **Trustworthy**: Every answer comes with source document citations

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¤– **RAG-based Q&A** | Retrieves relevant document chunks and generates grounded answers |
| ğŸ§  **Conversation Memory** | Remembers last 6 messages for follow-up questions |
| ğŸ’¬ **Slang Understanding** | Preprocesses 35+ common abbreviations (idk, uk, cgpa, etc.) |
| ğŸ¨ **Modern Web UI** | Minimalist, animated React frontend inspired by piplanning.io |
| ğŸ“ **Source Citations** | Shows which document the answer came from |
| ğŸ’¡ **Suggested Questions** | Clickable question chips for guided interaction |
| ğŸ“„ **Multi-format Ingestion** | Supports PDF, DOCX, and TXT files |
| ğŸ–¥ï¸ **Streamlit Backup** | Alternative Streamlit interface available as fallback |
| ğŸ”’ **Fully Local** | Runs entirely on your machine â€” no API keys, no cloud |

---

## ğŸ“ Project Structure

```
LLM-Based-Knowledge-Retrieval-System/
â”‚
â”œâ”€â”€ data/                          # ğŸ“„ College documents (add your own here)
â”‚   â”œâ”€â”€ sample_policy.txt          # General policies (attendance, grading, library)
â”‚   â”œâ”€â”€ placement_cell_guidelines.txt  # Placement eligibility, company stats
â”‚   â”œâ”€â”€ hostel_rules.txt           # Hostel timings, mess, visitor policy
â”‚   â”œâ”€â”€ fee_structure.txt          # Tuition, exam fees, scholarships, refund
â”‚   â”œâ”€â”€ anti_ragging_policy.txt    # Zero-tolerance policy, helplines
â”‚   â””â”€â”€ scholarship_info.txt       # Merit, need-based, government scholarships
â”‚
â”œâ”€â”€ rag_engine.py                  # ğŸ§  Core RAG engine (retrieval + LLM + memory)
â”œâ”€â”€ ingest.py                      # ğŸ“¥ Document ingestion pipeline (â†’ ChromaDB)
â”œâ”€â”€ api.py                         # ğŸŒ FastAPI backend (REST API for frontend)
â”œâ”€â”€ app.py                         # ğŸ–¥ï¸ Streamlit app (backup UI)
â”‚
â”œâ”€â”€ web-app/                       # âš›ï¸ React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                # Main chat interface component
â”‚   â”‚   â”œâ”€â”€ index.css              # Tailwind v4 theme (colors, animations)
â”‚   â”‚   â””â”€â”€ main.jsx               # React entry point
â”‚   â”œâ”€â”€ index.html                 # HTML shell
â”‚   â”œâ”€â”€ vite.config.js             # Vite + Tailwind plugin config
â”‚   â””â”€â”€ package.json               # Node.js dependencies
â”‚
â”œâ”€â”€ assets/                        # ğŸ–¼ï¸ README images
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ start.sh                       # Linux/Mac startup script
â”œâ”€â”€ start.bat                      # Windows startup script
â””â”€â”€ .gitignore
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **LLM** | [Ollama](https://ollama.ai) (Llama 3.2 3B) | Local language model for answer generation |
| **Vector DB** | [ChromaDB](https://www.trychroma.com) | Store and retrieve document embeddings |
| **Embeddings** | sentence-transformers/all-MiniLM-L6-v2 | Convert text to vector embeddings |
| **Backend** | [FastAPI](https://fastapi.tiangolo.com) | REST API serving the RAG engine |
| **Frontend** | [React](https://react.dev) + [Vite](https://vitejs.dev) | Modern web interface |
| **Styling** | [Tailwind CSS v4](https://tailwindcss.com) | Utility-first CSS framework |
| **Orchestration** | [LangChain](https://langchain.com) | RAG pipeline, prompt management |
| **Backup UI** | [Streamlit](https://streamlit.io) | Quick-deploy alternative interface |

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Node.js 18+** and **npm**
- **Ollama** installed and running ([install guide](https://ollama.ai/download))

### 1. Clone the Repository

```bash
git clone https://github.com/MohitGoel109/LLM-Based-Knowledge-Retrieval-System.git
cd LLM-Based-Knowledge-Retrieval-System
```

### 2. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 3. Pull the LLM Model

```bash
ollama pull llama3.2:3b
```

### 4. Add Your Documents

Place your college PDF, DOCX, or TXT files in the `data/` directory. Sample files are provided to get started.

### 5. Ingest Documents into Vector DB

```bash
python ingest.py
```

This converts your documents into vector embeddings and stores them in ChromaDB.

### 6. Start the Backend

```bash
python api.py
# Server starts at http://localhost:8000
```

### 7. Start the Frontend

```bash
cd web-app
npm install
npx vite --port 5173
# Opens at http://localhost:5173
```

### Alternative: Streamlit UI

```bash
streamlit run app.py
```

---

## ğŸ” How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Student    â”‚     â”‚   FastAPI API   â”‚     â”‚   RAG Engine     â”‚
â”‚   (React)    â”‚â”€â”€â”€â”€â–¶â”‚   (api.py)      â”‚â”€â”€â”€â”€â–¶â”‚  (rag_engine.py) â”‚
â”‚              â”‚     â”‚                 â”‚     â”‚                  â”‚
â”‚  "What's the â”‚     â”‚  POST /chat     â”‚     â”‚  1. Expand slang â”‚
â”‚   attendance â”‚     â”‚  {message,      â”‚     â”‚  2. Retrieve docsâ”‚
â”‚   policy?"   â”‚     â”‚   history}      â”‚     â”‚  3. Build prompt â”‚
â”‚              â”‚â—€â”€â”€â”€â”€â”‚                 â”‚â—€â”€â”€â”€â”€â”‚  4. LLM answer   â”‚
â”‚  Answer +    â”‚     â”‚  {answer,       â”‚     â”‚  5. Save history â”‚
â”‚  Sources     â”‚     â”‚   sources}      â”‚     â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                               â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                                               â”‚  ChromaDB  â”‚
                                               â”‚ (Vector DB)â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Student asks a question** (possibly with slang like "idk about the attendance rules")
2. **Slang preprocessing** expands it to "I don't know about the attendance rules"
3. **Vector retrieval** finds the 3 most relevant document chunks from ChromaDB
4. **LLM generates an answer** using only the retrieved context + conversation history
5. **Source citations** are returned so students can verify the information

---

## ğŸ’¬ Slang & Abbreviation Support

The system understands common student language:

| Slang | Expands To |
|-------|-----------|
| `uk` | you know |
| `idk` | I don't know |
| `wdym` | what do you mean |
| `tbh` | to be honest |
| `pls` / `plz` | please |
| `wanna` | want to |
| `gonna` | going to |
| `cgpa` | CGPA cumulative grade point average |
| `hod` | Head of Department |
| `kt` | backlog subject |

...and 25+ more. See [`rag_engine.py`](rag_engine.py) for the full list.

---

## ğŸ“„ Sample Data Included

The project comes with 6 realistic sample documents:

| Document | Content |
|----------|---------|
| `sample_policy.txt` | Attendance, grading system, library rules, IT lab guidelines |
| `placement_cell_guidelines.txt` | Eligibility criteria, CGPA cutoffs, company visit history, placement stats |
| `hostel_rules.txt` | Timings, mess schedule, room allocation, visitor policy, prohibited items |
| `fee_structure.txt` | Tuition, exam fees, hostel charges, scholarships, refund policy |
| `anti_ragging_policy.txt` | Definitions, punishments, reporting channels, helpline numbers |
| `scholarship_info.txt` | Merit-based, need-based, government, sports scholarships |

> **Note:** These are sample documents for demonstration. Replace them with your actual college documents for production use.

---

## âš ï¸ Current Limitations

- **Offline LLM**: Requires Ollama running locally with sufficient RAM (~4 GB for Llama 3.2 3B)
- **Sample data only**: Real college documents need to be added for actual deployment
- **No authentication**: Currently no user login system â€” anyone with access can query
- **Single-session memory**: Conversation history resets when the server restarts
- **English only**: The slang dictionary and LLM are optimized for English
- **No document upload UI**: Documents must be manually added to `data/` and re-ingested via CLI

---

## ğŸ—ºï¸ Roadmap / What's Left

- [ ] **Add real college documents** (PDFs from administration)
- [ ] **Document upload via UI** â€” drag-and-drop documents through the web interface
- [ ] **User authentication** â€” student login with college roll number
- [ ] **Persistent chat history** â€” save conversations to a database
- [ ] **Multi-language support** â€” Hindi + English for broader accessibility
- [ ] **Admin dashboard** â€” view query analytics, popular questions, system health
- [ ] **Mobile responsive** â€” optimize the UI for phone screens
- [ ] **Deploy to production** â€” host on a college server or cloud platform

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Commit your changes (`git commit -m 'Add your feature'`)
4. Push to the branch (`git push origin feature/your-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

<p align="center">
  Made with â¤ï¸ for college students who deserve better access to information
</p>